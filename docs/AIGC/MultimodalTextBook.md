---
sidebar_position: 9
---

# 一坤年教育视频打造一个专为VLM模型训练的多模态教科书数据集
最近达摩院开源了一个高质量的多模态训练数据集，[论文地址](https://arxiv.org/abs/2501.00958),[github链接](https://github.com/DAMO-NLP-SG/multimodal_textbook)，提出了一种用于视觉语言预训练的多模态教科书式语料库，旨在解决现有交错数据集存在的问题，提升视觉语言模型（VLM）的预训练效果。
## 研究背景
视觉语言模型的发展：得益于大语言模型（LLM）的进步和高质量多模态训练语料库的创建，视觉语言模型在多种视觉任务中表现出色。多模态语料库通常由图像 - 文本对组成，用于对齐图像和文本描述，预训练使 LLM 能够感知和解释视觉信息。
现有交错数据集的问题：现有的图像 - 文本交错语料库虽更自然灵活，但存在图像 - 文本关系松散、图像序列逻辑连贯性差、知识密度低等问题，影响了学习效果。
教学视频资源的利用：互联网上的大量教学视频包含丰富的基础知识和详细讲解，是理想的训练数据来源，但在 VLM 训练中尚未得到充分利用。
多模态教科书的构建
## 数据收集
构建知识分类体系：利用 LLM 提出涵盖六个学科和 3915 个知识点的四层知识分类体系（学科→课程→子课程→知识点），通过 YouTube 搜索 API 收集相关教学视频，每个知识点保留前 50 个视频，共收集 159,565 个视频。
视频筛选与去重：基于视频 ID 去重，通过 LLM 审查视频元数据（标题、描述、评论）排除不相关、色情或非法内容，保留 75,000 个高质量视频。
视频到教科书的处理流程
视频级别提取与筛选：提取视频音频并转录为文本（ASR），使用 Qwen2-72B-Instruct 优化 ASR 文本以提高流畅性和连贯性；依据规则（非英语、时长过短、ASR 文本过少）和 LLM 评估（相关性、知识密度、转录质量）筛选视频，保留 75,000 个高质量视频。
片段级别提取与筛选：依据 ASR 时间戳将长视频分割为 10 - 20 秒的片段，合并不完整的 ASR 段；使用 VideoLlama2 为片段生成字幕，通过计算字幕与 ASR 的文本相似度筛选掉无视觉知识的片段，但保留其 ASR 转录。
关键帧级别提取与筛选：使用 SSIM 算法检测关键帧，提取关键帧中的文本、符号和公式（OCR），过滤掉低信息量的关键帧和相似的 OCR 结果。最后将处理后的关键帧、ASR 和 OCR 文本按时间顺序交错排列，构建多模态教科书。
多模态教科书的分析
## 总体统计：
合成的知识分类体系包含 6 个学科、55 门课程和 3915 个知识点，自动收集的 159K 英语教学视频经处理后保留 75K 视频（22,697 课时），平均时长 18 分钟，从中提取 6.5M 关键帧和 0.75B 文本（ASR+OCR）标记，组合成 610K 交错样本，每个样本平均含 10.7 个关键帧和 1,297 个文本标记。
与现有数据集对比
图像和文本分布：相比现有图像 - 文本配对数据集和网页中心交错数据集，多模态教科书在平均图像数量和文本标记数量上更优，如平均每个样本含 10.7 个图像，高于 MMC4 的 5.7 个和 OBELICS 的 4.1 个。
样本内图像相关性：设计的 InSI-SIM 指标显示，多模态教科书在样本内图像相关性上表现出色，平均得分 0.686，远高于 OBELICS 的 0.345，且随样本图像数量增加，其相关性保持稳定，而其他数据集下降明显。
## 实验结果
### 实验设置
- 基线模型：
采用 LLaVA-1.5-7B 和 Idefics2-8B 作为基线模型，分别进行持续预训练（从预训练模型开始）和从头预训练（随机初始化投影器），并在多个数据集上进行对比实验。
评估方法：在 TextVQA、OKVQA、ScienceQA、MathVista、MathVision、MathVerse 等基准上进行评估，采用 few-shot 设置，计算模型准确率。
主要结果
- 性能提升：
在多模态教科书上预训练后，LLaVA-1.5 和 Idefics-8B 在七个基准上均有显著提升，如 ScienceQA 上零样本和少样本设置分别提升超 20%，MathVista 上平均提升 5.3% 和 6.4%。
上下文学习能力增强：在 OKVQA 和 TextVQA 等通用基准上，多模态教科书在少样本设置下也有改进，如在 TextVQA 中，2-shot 和 4-shot 设置下超过 OBELICS，这归因于其视频中心的交错设计提供了更连贯的上下文，增强了 VLM 的上下文学习能力。
# 分析
- 模型对交错上下文的关注：
通过 “Cheat Test” 实验发现，在多模态教科书上预训练的 VLM 能更有效地关注交错上下文，从 1-shot 到 2-shot 作弊场景中，其性能下降幅度小于其他数据集。
- 图像顺序的影响：
打乱交错数据集中图像顺序的实验表明，多模态教科书对图像顺序打乱敏感，性能显著下降，而网页中心数据集受影响较小，证实了其图像连贯性和紧密对齐的图像 - 文本关系对学习复杂知识和推理逻辑的重要性。
- 指令微调后的性能：
在 LLaVA665K 语料上进行指令微调后，多模态教科书在 Mathvista 等基准上提升显著，表明预训练所学知识可迁移到指令微调阶段，有利于下游任务。
消融实验
- ASR 优化的影响：
使用原始 ASR 文本会使模型性能下降，优化后的 ASR 文本降低了困惑度，更接近标准训练语料，对提升模型语言能力至关重要。
- OCR 整合的作用：
整合 OCR 能提供额外改进，特别是在 TextVQA 和 MathVista 等基准上，但低质量 OCR 会引入噪声，选择可靠工具提取高质量 OCR 至关重要。
- 关键帧提取方法的比较：
对比像素级（OpenCV absdiff）、结构算法（SSIM）和语义模型（CLIP-ViT-L）三种关键帧提取方法，发现 SSIM 在处理教学视频中的抽象图表或几何图像时效果最佳，能提供更好的训练性能。