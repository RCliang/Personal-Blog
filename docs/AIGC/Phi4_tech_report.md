---
sidebar_position: 6
---

# Phi-4 Technical Report
微软最近推出了Phi-4，号称最先进的小型大模型，专攻数学推理，甚至超越了同类更大模型。[论文链接](https://arxiv.org/abs/2412.08905)。本文就主要来精读一下这篇技术报告，内容其实也比较简单，主要介绍了Phi-4的训练过程和模型性能。这款140亿参数的大模型在训练过程中大量使用合成数据，通过创新的合成数据生成方法、优化训练课程和数据混合以及引入新技术，在推理相关任务上表现出色。我们主要看看他的数据策略和训练方法。

## 模型亮点
数据策略创新：训练数据以合成数据为主，通过多种技术生成，包括多智能体提示、自我修订工作流和指令反转，同时精心策划和筛选有机数据作为补充，确保数据的多样性、准确性和相关性。
多智能体提示等技术运用：运用多智能体提示、自我修订工作流和指令反转等技术生成合成数据。例如在生成代码相关合成数据时，通过指令反转技术，利用现有代码片段生成相应指令，确保指令与输出的一致性
数据生成原则遵循：生成合成数据时遵循多样性、细微差别与复杂性、准确性和思维链等原则。如在种子策划阶段，从多个领域获取高质量种子，涵盖网页、书籍和代码库等，种子数据通过多步提示工作流程被转化为合成数据。这一过程涉及对给定段落中大部分有用内容进行改写，将其转变为练习、讨论或结构化推理任务。确保数据的多样性和高质量
有机数据来源广泛：精心筛选有机数据来源，包括网页内容、许可书籍和代码库等，如从这些来源中提取具有高复杂性、推理深度和教育价值的内容作为合成数据生成的种子
为了增强模型根据指令生成输出的能力，采用了指令反转技术。该技术旨在使模型更好地理解和遵循指令，从而生成更准确、相关的输出，特别是在涉及代码生成和其他任务时。
多语言数据的处理：为确保模型能处理多种语言，从 CommonCrawl 和 Wikipedia 获取多语言数据集，并通过语言识别模型和分类器进行筛选和处理。从大量网页数据堆中选取一小部分高质量文档，使用基于约 106 个由大语言模型生成的注释训练的小型（非大语言模型）分类器。此方法往往会过度索引与 STEM 相关的关键词，因此创建了一个专门的管道来增强高质量的非 STEM 内容
自定义提取和清理管道
训练方法优化：采用两阶段训练策略，根据数据的质量和效果调整训练过程，增加合成数据的分配，同时对高质量有机数据进行筛选和处理，提高模型的泛化能力。
训练阶段划分与数据侧重：采用两阶段训练策略，第一阶段主要使用过滤后的网页数据，第二阶段则以合成数据为主，并分配少量超过滤和推理密集型网页数据。在第二阶段训练中，随着合成数据规模和复杂性的增加，发现对 phi-3 系列模型而言，增加合成数据的迭代次数比提供更多网页数据更有益
数据混合比例调整依据：通过消融实验确定训练数据的混合比例，根据不同来源数据（合成、网页改写、过滤网页、目标获取和有机数据、代码数据）对模型性能的影响来分配训练令牌。最终确定的 phi-4 预训练数据混合方案为，将 30% 的训练令牌分配给网页和网页改写数据源，40% 来自合成数据，20% 给代码数据，10% 给目标获取来源
针对每个模型规模进行两次训练运行，这些训练是在第一阶段预训练检查点的基础上进行的，并且使用相同数量的训练令牌。对合成数据进行更多的迭代（如 12 个轮次）比提供更多的网页令牌更有益。这表明在一定范围内，增加合成数据的训练次数有助于提升模型性能，即使合成数据的总量没有增加（因为是固定的子样本）  
在所有的训练运行中，独特合成令牌的数量是固定的（是完整合成数据的一个子样本），但对这些数据的重复次数有所不同，分别为 4 个和 12 个轮次（epoch）。而其余的训练令牌则是来自网页来源的全新独特令牌。
上下文长度扩展与数据适配：在训练过程中包含一个中间训练阶段，将模型上下文长度从 4K 扩展到 16K。为此进一步筛选高质量非合成数据集，分离出长上下文样本，并创建满足长序列要求的合成数据集。同时调整训练参数，如降低学习率，增加训练令牌数量
训练超参数的确定：预训练约 10T tokens，使用线性预热和衰减策略，峰值学习率为 0.0003，恒定权重衰减为 0.1，全局批量大小为 5760。训练超参数通过短时间运行的插值调整，并在学习率预热阶段进行压力测试以确保稳定性
推理能力提升：在推理相关任务上表现优异，如在 GPQA 和 MATH 基准测试中超过其教师模型 GPT-4o，在 AMC-10 和 AMC-12 数学竞赛中表现出色，证明其推理能力并非源于过拟合或数据污染。
## 模型应用
学术研究：在多个学术基准测试中表现出色，可用于学术研究，为相关领域提供有力支持。
实际问题解决：在实际问题解决中发挥作用，如在数学竞赛、问答任务等方面展现出较强能力，可应用于教育、科研等领域。
## 模型不足
事实性知识幻觉：在处理事实性知识时可能出现幻觉，例如对人名相关问题可能给出虚构的回答。
指令遵循能力不足：在遵循详细指令方面不够熟练，特别是涉及特定格式要求的任务。
推理错误：即使在推理任务中也可能出现错误，如比较数字大小等简单问题。
## 未来展望
优化训练数据混合：进一步优化训练数据的混合比例，充分发挥合成数据和有机数据的优势，提高模型性能。
提高指令遵循能力：通过针对性的合成数据训练，增强模型严格遵循详细指令的能力，提升用户体验。
减少偏见和安全问题：持续改进数据处理和训练方法，减少模型在偏见、有害内容生成和安全方面的问题，确保模型的可靠性和安全性。